{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGOAL: 99% **TEST** ACCURACY\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "GOAL: 99% **TEST** ACCURACY\n",
    "'''\n",
    "\n",
    "# explore different architectures, data augmentation and regularization methods to determine a suitable range of parameters\n",
    "# TODO: use optuna to explore the hyperparameter spacej\n",
    "# TODO: report final hyperparameter values and test accuracy\n",
    "\n",
    "# SUBMIT:\n",
    "# TODO: \"informed discussion\" of approach to hyperparameter exploration / observations\n",
    "# TODO: submit use of optuna code\n",
    "# TODO: final performance of model\n",
    "# TODO: discussion of limitations of not using a separate validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"mps\")\n",
    "BATCHSIZE = 512\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd() #./datafiles/\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
    "\n",
    "LOSS_FN = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist(trial):\n",
    "\n",
    "    aff_alph = trial.suggest_float(\"affine_alpha\", 50.0, 70.0)\n",
    "\n",
    "    # Any data augmentation should be added to training\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomRotation(15), #already randomly samples in range\n",
    "        transforms.RandomAffine(25), #already randomly samples in range\n",
    "        transforms.ElasticTransform(alpha=aff_alph),\n",
    "        transforms.Normalize(mean=0.1307, std=0.3081),\n",
    "    ])\n",
    "\n",
    "    # Test data should have normalization applied, but no augmentation\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=0.1307, std=0.3081)\n",
    "    ])\n",
    "\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(DIR, train=False, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_output_size(input_size, padding, stride, kernel):   \n",
    "    return math.floor((input_size + 2*padding - kernel)/stride) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Model(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "        super().__init__()\n",
    "        n_layers = trial.suggest_int(\"n_layers\", 2, 3)\n",
    "        layers = []\n",
    "\n",
    "        in_exp = 0\n",
    "        img_size = 28\n",
    "        for i in range(n_layers):\n",
    "            out_exp = trial.suggest_int(\"n_units_l{}\".format(i), in_exp, 8)\n",
    "            in_channels = 2 ** in_exp\n",
    "            out_channels = 2 ** out_exp\n",
    "\n",
    "            kernel_size = 7 - (2*i)\n",
    "\n",
    "            # NOTE: Maria -> could vary kernel and padding more\n",
    "            layers.append(nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                padding='same'\n",
    "            ))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=1))\n",
    "            img_size = get_output_size(input_size=img_size, stride=2, kernel=2, padding=1)\n",
    "            # Batch Norm\n",
    "            layers.append(nn.BatchNorm2d(out_channels)) #NOTE: could play around with the placement\n",
    "\n",
    "            in_channels = out_channels\n",
    "            in_exp = out_exp\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.05, 0.25) #NOTE: Zach: Verify p.\n",
    "        # TODO: Maria: make this a variable amount\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.output_layer = nn.Linear(in_channels*img_size*img_size, CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.conv_layers(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        # print(f\"after dropout: {x.shape}\")\n",
    "\n",
    "        x = x.view(x.size(0), -1) \n",
    "        # print(f\"after reshape: {x.shape}\")\n",
    "        x = self.output_layer(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "def define_model(trial):\n",
    "    model = MNIST_Model(trial)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_old(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 4)\n",
    "    layers = []\n",
    "\n",
    "    in_channels = 1\n",
    "    for i in range(n_layers):\n",
    "        out_channels = trial.suggest_int(\"n_units_l{}\".format(i), in_channels, 128)\n",
    "        kernel_size = 7 - (2*i)\n",
    "        print(f\"kernel_size: {kernel_size}\")\n",
    "\n",
    "        # NOTE: Maria -> could vary kernel and padding more\n",
    "        layers.append(nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding='same'\n",
    "        ))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=1))\n",
    "        # Batch Norm\n",
    "        layers.append(nn.BatchNorm2d(out_channels)) #NOTE: could play around with the placement\n",
    "\n",
    "        print(f\"in_channels: {in_channels} out_channels: {out_channels}\")\n",
    "        in_channels = out_channels\n",
    "    \n",
    "    # TODO: Maria: Figure this out\n",
    "    # use_average_pool = trial.suggest_int(\"use_average_pool\", 0, 1) #NOTE: Maria: ask trevor about this?\n",
    "    # if use_average_pool:\n",
    "    #     layers.append(nn.AdaptiveAvgPool2d(output_size=(1,1)).squeeze()) #NOTE: Maria: this does not work\n",
    "\n",
    "    # n_linear_layers = trial.suggest_int(\"n_linear_layers\", 1, 2)\n",
    "    p = trial.suggest_float(\"dropout_l{}\".format(i), 0.05, 0.25) #NOTE: Zach: Verify p.\n",
    "\n",
    "    # TODO: delete this... there is still an error with this version but seems like a more important one to solve\n",
    "    layers.append(nn.Dropout(p))\n",
    "    layers.append(nn.Linear(in_channels, CLASSES))\n",
    "\n",
    "    # if n_linear_layers == 1:\n",
    "    #     layers.append(nn.Dropout(p))\n",
    "    #     layers.append(nn.Linear(in_channels, CLASSES))\n",
    "        \n",
    "    # if n_linear_layers == 2:\n",
    "    #     intermediate_channels = in_channels/2\n",
    "    #     layers.append(nn.Linear(in_channels, intermediate_channels))\n",
    "    #     layers.append(nn.Dropout(p))\n",
    "    #     layers.append(nn.Linear(intermediate_channels, CLASSES))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # TODO Zach: Add optimizer, and weight decay.\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\"])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-1, log=True)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist(trial)\n",
    "    \n",
    "    # Initialize variables for tracking the best accuracy and the number of epochs since improvement\n",
    "    best_patience = 0\n",
    "    epochs_since_improvement = 0\n",
    "    best_accuracy = 0  # Initialize to 0 for accuracy\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = LOSS_FN(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES: #TODO: discuss getting rid of this \n",
    "                    break\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy \n",
    "            if epochs_since_improvement > 0:\n",
    "                if best_patience < epochs_since_improvement:\n",
    "                    best_patience = epochs_since_improvement\n",
    "                epochs_since_improvement = 0\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    print(f\"Best patience value: {best_patience}\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-31 21:42:41,811] A new study created in memory with name: no-name-74bc0c37-a64a-4c84-b67d-8c7b141e18c5\n",
      "[I 2023-10-31 21:43:02,700] Trial 0 finished with value: 0.976171875 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'n_units_l1': 8, 'dropout_l1': 0.22249162975337988, 'optimizer': 'RMSprop', 'weight_decay': 0.005210952085501617, 'lr': 0.0023514662160008452, 'affine_alpha': 56.42539390244004}. Best is trial 0 with value: 0.976171875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best patience value: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-10-31 21:43:26,298] Trial 1 failed with parameters: {'n_layers': 3, 'n_units_l0': 8, 'n_units_l1': 8, 'n_units_l2': 8, 'dropout_l2': 0.21609557771115817, 'optimizer': 'RMSprop', 'weight_decay': 0.0007491812529969676, 'lr': 4.2356536168481974e-05, 'affine_alpha': 57.49916045559333} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/envs/torch-nightly/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/0v/1rrf835166g6l4b55txmksjm0000gn/T/ipykernel_88425/2699304349.py\", line 47, in objective\n",
      "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
      "KeyboardInterrupt\n",
      "[W 2023-10-31 21:43:26,299] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mariavmihu/Documents/SYDE-599/syde-599-assignment2/brainstorming.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariavmihu/Documents/SYDE-599/syde-599-assignment2/brainstorming.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mariavmihu/Documents/SYDE-599/syde-599-assignment2/brainstorming.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, timeout\u001b[39m=\u001b[39;49m\u001b[39m600\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariavmihu/Documents/SYDE-599/syde-599-assignment2/brainstorming.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pruned_trials \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mget_trials(deepcopy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, states\u001b[39m=\u001b[39m[TrialState\u001b[39m.\u001b[39mPRUNED])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariavmihu/Documents/SYDE-599/syde-599-assignment2/brainstorming.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m complete_trials \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mget_trials(deepcopy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, states\u001b[39m=\u001b[39m[TrialState\u001b[39m.\u001b[39mCOMPLETE])\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-nightly/lib/python3.8/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-nightly/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-nightly/lib/python3.8/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-nightly/lib/python3.8/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-nightly/lib/python3.8/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/mariavmihu/Documents/SYDE-599/syde-599-assignment2/brainstorming.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariavmihu/Documents/SYDE-599/syde-599-assignment2/brainstorming.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         \u001b[39m# Get the index of the max log-probability.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariavmihu/Documents/SYDE-599/syde-599-assignment2/brainstorming.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         pred \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mariavmihu/Documents/SYDE-599/syde-599-assignment2/brainstorming.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39;49meq(target\u001b[39m.\u001b[39;49mview_as(pred))\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariavmihu/Documents/SYDE-599/syde-599-assignment2/brainstorming.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m accuracy \u001b[39m=\u001b[39m correct \u001b[39m/\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mlen\u001b[39m(valid_loader\u001b[39m.\u001b[39mdataset), N_VALID_EXAMPLES)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariavmihu/Documents/SYDE-599/syde-599-assignment2/brainstorming.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mif\u001b[39;00m accuracy \u001b[39m>\u001b[39m best_accuracy:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=2, timeout=600)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment2-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
